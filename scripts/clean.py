"""
æ¸…ç†æ–‡æ¡£ä¸­çš„é¡µçœ‰ã€é¡µç ã€ç« èŠ‚æ ‡è®°
"""

import re
from pathlib import Path


def clean_document(text: str) -> str:
    """
    æ¸…ç†æ–‡æ¡£æ ¼å¼

    ç§»é™¤ï¼š
    1. é¡µç ï¼ˆå•ç‹¬ä¸€è¡Œçš„æ•°å­—ï¼‰
    2. é¡µçœ‰ï¼ˆå¦‚ "Reminiscence of a Stock Operator"ï¼‰
    3. ç« èŠ‚æ ‡è®°ï¼ˆå•ç‹¬çš„ç½—é©¬æ•°å­— I, II, IIIï¼‰
    4. å¤šä½™çš„ç©ºè¡Œ
    """

    lines = text.split("\n")
    cleaned_lines = []

    for i, line in enumerate(lines):
        line_stripped = line.strip()

        # è·³è¿‡ç©ºè¡Œï¼ˆä½†ä¿ç•™ä¸€äº›ç©ºè¡Œç”¨äºæ®µè½åˆ†éš”ï¼‰
        if not line_stripped:
            # é¿å…è¿ç»­å¤šä¸ªç©ºè¡Œ
            if cleaned_lines and cleaned_lines[-1] != "":
                cleaned_lines.append("")
            continue

        # è§„åˆ™1: è·³è¿‡çº¯æ•°å­—è¡Œï¼ˆé¡µç ï¼‰
        if re.match(r"^\d+$", line_stripped):
            continue

        # è§„åˆ™2: è·³è¿‡å•ä¸ªç½—é©¬æ•°å­—ï¼ˆç« èŠ‚æ ‡è®°ï¼‰
        if re.match(r"^[IVX]+$", line_stripped) and len(line_stripped) <= 5:
            continue

        # è§„åˆ™3: è·³è¿‡å¸¸è§çš„é¡µçœ‰æ¨¡å¼
        if re.match(
            r"^Reminiscence[s]? of a Stock Operator$", line_stripped, re.IGNORECASE
        ):
            continue

        # è§„åˆ™4: è·³è¿‡å…¶ä»–å¸¸è§é¡µçœ‰æ ¼å¼
        headers = [
            r"^Chapter \d+$",
            r"^CHAPTER [IVX]+$",
            r"^\d+\s*$",  # çº¯æ•°å­—ï¼ˆé¡µç å˜ä½“ï¼‰
        ]

        is_header = False
        for header_pattern in headers:
            if re.match(header_pattern, line_stripped, re.IGNORECASE):
                is_header = True
                break

        if is_header:
            continue

        # ä¿ç•™æ­£å¸¸å†…å®¹è¡Œ
        cleaned_lines.append(line)

    # åˆå¹¶å›æ–‡æœ¬
    cleaned_text = "\n".join(cleaned_lines)

    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆ3ä¸ªä»¥ä¸Šç©ºè¡Œç¼©å‡ä¸º2ä¸ªï¼‰
    cleaned_text = re.sub(r"\n{3,}", "\n\n", cleaned_text)

    return cleaned_text.strip()


def clean_file(input_path: Path, output_path: Path = None):
    """
    æ¸…ç†æ–‡ä»¶

    Args:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸º input_cleaned.txtï¼‰
    """
    # è¯»å–åŸå§‹æ–‡ä»¶
    with open(input_path, "r", encoding="utf-8") as f:
        original_text = f.read()

    print(f"ğŸ“„ åŸå§‹æ–‡ä»¶: {input_path}")
    print(f"   å­—ç¬¦æ•°: {len(original_text)}")
    print(f"   è¡Œæ•°: {len(original_text.split(chr(10)))}")

    # æ¸…ç†
    cleaned_text = clean_document(original_text)

    print(f"\nâœ¨ æ¸…ç†å:")
    print(f"   å­—ç¬¦æ•°: {len(cleaned_text)}")
    print(f"   è¡Œæ•°: {len(cleaned_text.split(chr(10)))}")

    # ä¿å­˜
    if output_path is None:
        output_path = (
            input_path.parent / f"{input_path.stem}_cleaned{input_path.suffix}"
        )

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(cleaned_text)

    print(f"\nâœ… å·²ä¿å­˜åˆ°: {output_path}")

    # æ˜¾ç¤ºç¤ºä¾‹
    print(f"\nğŸ“ æ¸…ç†åçš„å‰500å­—ç¬¦:")
    print("=" * 60)
    print(cleaned_text[:500])
    print("=" * 60)


def clean_directory(input_dir: Path, output_dir: Path = None):
    """
    æ‰¹é‡æ¸…ç†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
    """
    if output_dir is None:
        output_dir = input_dir / "cleaned"

    output_dir.mkdir(exist_ok=True)

    # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
    txt_files = list(input_dir.glob("*.txt"))

    print(f"æ‰¾åˆ° {len(txt_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶\n")

    for txt_file in txt_files:
        print(f"å¤„ç†: {txt_file.name}")
        clean_file(txt_file, output_dir / txt_file.name)
        print()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ¸…ç†æ–‡æ¡£ä¸­çš„é¡µçœ‰å’Œé¡µç ")
    parser.add_argument("input", type=Path, help="è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•")
    parser.add_argument("--output", "-o", type=Path, help="è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--batch", "-b", action="store_true", help="æ‰¹é‡å¤„ç†ç›®å½•")

    args = parser.parse_args()

    if args.batch:
        clean_directory(args.input, args.output)
    else:
        clean_file(args.input, args.output)
