# ============ 模型配置 ============
# GGUF模型文件路径
GGUF_MODEL_PATH=./models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

# Embedding模型（HuggingFace模型名）
EMBEDDING_MODEL=./sentence-transformers/paraphrase-MiniLM-L6-v2

# Reranker模型
RERANKER_MODEL=./BAAI/bge-reranker-base

# ============ 路径配置 ============
DATA_PATH=./data
VECTOR_STORE_PATH=./vector_store
LOG_PATH=./logs
MODELS_PATH=./models

# ============ LLM参数 ============
N_CTX=4096              # 上下文窗口大小
N_THREADS=8             # CPU线程数（建议设为CPU核心数）
N_GPU_LAYERS=0          # GPU层数（0=纯CPU，35=全部用GPU）
N_BATCH=512             # 批处理大小
TEMPERATURE=0.7         # 生成温度 (0.0-2.0，越低越确定)
MAX_TOKENS=512          # 最大生成token数
TOP_P=0.95              # Nucleus sampling
REPEAT_PENALTY=1.15     # 重复惩罚 (1.0=无惩罚)

# ============ 检索参数 ============
INITIAL_K=20            # FAISS粗排返回文档数
FINAL_K=3               # Reranker精排返回文档数
CHUNK_SIZE=1000         # 文档块大小（字符数）
CHUNK_OVERLAP=200       # 块之间重叠大小

# ============ 服务器配置 ============
SERVER_HOST=0.0.0.0
SERVER_PORT=7860
RELOAD=False            # 开发模式自动重载
LOG_LEVEL=info          # debug, info, warning, error
SHARE=False             # Gradio公网分享

# ============ 其他配置 ============
# 如果使用HuggingFace镜像
# HF_ENDPOINT=https://hf-mirror.com
